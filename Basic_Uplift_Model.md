# Uplift åŸºç¡€

## ç®€ä»‹

Uplift modelsç”¨äºé¢„æµ‹ä¸€ä¸ªtreatmentçš„**å¢é‡**åé¦ˆä»·å€¼ï¼Œæ¯”å¦‚ç»™ç”¨æˆ·**æŠ•æ”¾å¹¿å‘Šåå…¶è½¬åŒ–æ„æ„¿çš„å¢é‡**ã€‚æˆ‘ä»¬ä¸å¯èƒ½å¯¹åŒä¸€ä¸ªç”¨æˆ·å³treatedåˆcontroledï¼Œä½†æ˜¯å€ŸåŠ©ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Œå¯ä»¥å¾—åˆ°ç›¸ä¼¼çš„ç”¨æˆ·å¤§è‡´ä¼šæ€ä¹ˆååº”ã€‚æ¯ä¸€ä¸ªç”¨æˆ·ä¼šè·å¾—ä¸€ä¸ª**ä¼°è®¡ lift score**ï¼Œç”¨äºæŒ‡å¯¼åœ¨ä¸åŒç”¨æˆ·äººç¾¤ä¸Šå®æ–½å·®å¼‚åŒ–ç­–ç•¥ã€‚ï¼ˆuplift modelçš„ç›®æ ‡æ˜¯ä¼°è®¡ **CATE**ï¼‰

<img src="./img/Basic/029.png" style="zoom:50%;" />

**Response model v.s. Uplift model**

ä¸¾ä¸ªğŸŒ°ï¼š

| ç”¨æˆ· | è½¬åŒ–ç‡ | æŠ•æ”¾å¹¿å‘Šåè½¬åŒ–ç‡ | uplift |
| :--: | :----: | :--------------: | :----: |
|  A   |   1%   |       10%        |   9%   |
|  B   |  10%   |       0.1%       |  0.1%  |

- Response modelï¼š**çœ‹è½¬åŒ–æ¦‚ç‡ï¼Œ**åŸºäºResponseå€¼â€”â€”ä¼šå€¾å‘äºç»™BæŠ•å¹¿å‘Š
- Uplift modelï¼š**çœ‹è½¬åŒ–æ¦‚ç‡æå‡ï¼Œ**åŸºäºdelta_Response/upliftå€¼å»ºæ¨¡â€”â€”ä¼šå€¾å‘äºç»™AæŠ•æ”¾å¹¿å‘Š

**æ³¨æ„ï¼šUplift Modelæ˜¯åœ¨ä¼°è®¡ITEçš„æ–¹æ³•ï¼Œå¹¶ä¸æ˜¯ç›´æ¥ä¼°è®¡ATEï¼**

## Meta-learner

è¿™é‡Œä»‹ç»Meta-learnerï¼Œå¯¹å¯¹ç…§ç»„å’Œå®éªŒç»„çš„ç»“å±€è¿›è¡Œå»ºæ¨¡ï¼ˆçº¿æ€§ã€æ ‘åˆ°æ·±åº¦å­¦ä¹ éƒ½å¯ï¼‰ï¼Œåˆ©ç”¨æ‹Ÿåˆçš„æ¨¡å‹ï¼ˆbase learnerï¼‰é¢„æµ‹ITE, CATE, ATEã€‚

### **S-learner**

æŠŠ**å¹²é¢„Tä½œä¸ºä¸€ä¸ª0-1åˆ†ç±»ç‰¹å¾ï¼Œå»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼Œè®¡ç®—ç»™å®šåå˜é‡Xæ—¶ä¸åŒå¹²é¢„Tçš„ uplift å€¼**ã€‚

<img src="./img/Basic/030.png" style="zoom:70%;" />

**é—®é¢˜ï¼š**

ä¸“æ³¨äºå¯¹responseæœ¬èº«çš„é¢„æµ‹ï¼Œè€Œå¿½ç•¥äº†å¯¹delta_responseçš„å…³æ³¨ï¼Œ**multi-treatmentä¸éœ€è¦é¢å¤–å¢åŠ æ¨¡å‹**ã€‚

å½“**å®éªŒç»„å’Œå¯¹ç…§ç»„ATEå·®å¼‚è¾ƒå°**æ—¶ï¼Œéš¾ä»¥å­¦å‡†

**è¯¦è§£ï¼š**

â€œSâ€æ˜¯singleçš„æ„æ€ï¼Œæ˜¯æŒ‡ä½¿ç”¨ä¸€ä¸ªé¢„æµ‹æ¨¡å‹å®Œæˆupliftä¼°è®¡ã€‚å…·ä½“æ­¥éª¤åŒ…æ‹¬

- **Step1ï¼šåŸºäºå˜é‡Xå’Œå¹²é¢„Wè®­ç»ƒé¢„æµ‹æ¨¡å‹**
- **Step2ï¼šåˆ†åˆ«ä¼°è®¡å¹²é¢„å’Œä¸å¹²é¢„æ—¶çš„å¾—åˆ†ï¼Œå·®å€¼å³ä¸ºå¢é‡**

ã€ä¼˜ç‚¹ã€‘S-Learnerç®€å•ç›´è§‚ã€ç›´æ¥ä½¿ç”¨æ—¢æœ‰é¢„æµ‹ç®—æ³•ï¼›é¢„æµ‹ä»…**ä¾èµ–ä¸€ä¸ªæ¨¡å‹**ï¼Œé¿å…äº†å¤šæ¨¡å‹çš„è¯¯å·®ç´¯ç§¯ï¼›æ›´å¤šçš„æ•°æ®å’Œç‰¹å¾å·¥ç¨‹å¯¹é¢„æµ‹å‡†ç¡®ç‡æœ‰åˆ©ã€‚

ã€ç¼ºç‚¹ã€‘ä½†æ˜¯è¯¥æ–¹æ³•**ä¸ç›´æ¥å»ºæ¨¡uplift**ï¼›ä¸”éœ€è¦é¢å¤–è¿›è¡Œç‰¹å¾å·¥ç¨‹å·¥ä½œ(ç”±äºæ¨¡å‹æ‹Ÿåˆçš„æ˜¯Yï¼Œæ‰€ä»¥è‹¥Wç›´æ¥ä½œä¸ºä¸€ä¸ªç‰¹å¾æ”¾è¿›å»ï¼Œå¯èƒ½ç”±äºå¯¹Yçš„é¢„æµ‹èƒ½åŠ›ä¸è¶³è€Œæœªå……åˆ†åˆ©ç”¨)ã€‚

### **T-learner**

å¯¹**å®éªŒç»„å’Œå¯¹ç…§ç»„åˆ†åˆ«å»ºæ¨¡ï¼Œå†è®¡ç®—ç»™å®šåå˜é‡Xæ—¶ uplift å€¼**ã€‚

<img src="./img/Basic/031.png" style="zoom:70%;" />

**é—®é¢˜ï¼š**

å¤šæ¨¡å‹å­˜åœ¨**è¯¯å·®ç´¯åŠ **ï¼›**multi-treatmentå¸¦æ¥æ¨¡å‹çš„æ•°é‡å¢åŠ **ï¼›å¿½ç•¥äº†å¯¹delta_responseçš„å…³æ³¨

**è¯¦è§£ï¼š**

"T"æ˜¯Twoçš„æ„æ€ï¼Œæ˜¯æŒ‡ç”¨ä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«å»ºæ¨¡å¹²é¢„ã€ä¸å¹²é¢„çš„æƒ…å†µï¼Œå–å·®å€¼ä½œä¸ºupliftã€‚å…·ä½“æ­¥éª¤ï¼š

- Step1ï¼šå¯¹treatmentç»„æ•°æ®å’Œcontrolç»„æ•°æ®åˆ†åˆ«è®­ç»ƒé¢„æµ‹æ¨¡å‹
- Step2ï¼šä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«æ‰“åˆ†

ã€ä¼˜ç‚¹ã€‘T-Learnerä¸€æ ·ç®€å•ç›´è§‚ã€ç›´æ¥ä½¿ç”¨æ—¢æœ‰é¢„æµ‹ç®—æ³•ï¼›**å°†ä¸åŒçš„æ•°æ®é›†ä¸­çš„å¢é‡æ•ˆæœè½¬æ¢ä¸ºæ¨¡å‹é—´çš„å·®å¼‚**ï¼Œä¸éœ€è¦å¤ªå¤šçš„ç‰¹å¾å·¥ç¨‹å·¥ä½œï¼›**å½“æœ‰éšæœºè¯•éªŒçš„æ•°æ®æ—¶è¯¥æ–¹æ³•ä½œä¸ºbaselineå¾ˆæ–¹ä¾¿ã€‚**

ã€ç¼ºç‚¹ã€‘è¯¥æ–¹æ³•å­˜åœ¨**åŒæ¨¡å‹è¯¯å·®ç´¯ç§¯é—®é¢˜**ï¼›åŒæ—¶å½“æ•°æ®å·®å¼‚è¿‡å¤§æ—¶(å¦‚æ•°æ®é‡ã€é‡‡æ ·åå·®ç­‰)ï¼Œå¯¹å‡†ç¡®ç‡å½±å“è¾ƒå¤§ã€‚

### **X-learner**

X-learner é€‚åˆ**å®éªŒç»„å’Œå¯¹ç…§ç»„æ ·æœ¬æ•°é‡å·®åˆ«è¾ƒå¤§åœºæ™¯**ã€‚

**æ­¥éª¤**

1. å¯¹å®éªŒç»„å’Œå¯¹ç…§ç»„åˆ†åˆ«æ‹Ÿåˆæ¨¡å‹

<img src="./img/Basic/032.png" style="zoom:70%;" />

2. äº¤å‰é¢„æµ‹ï¼šDiè¡¨ç¤ºæ ·æœ¬iå®é™…ç»“å±€å’Œé¢„ä¼°ç»“å±€ä¹‹é—´çš„å·®

<img src="./img/Basic/033.png" style="zoom:70%;" />

3. fit(D^1~ X^1)ï¼Œè®­ç»ƒå®éªŒç»„æ¨¡å‹ Ï„_1(x)_

   fit(D^0~ X^0)ï¼Œè®­ç»ƒå¯¹ç…§ç»„æ¨¡å‹ Ï„_0(x)

4. å¯¹ä¸¤ä¸ªç»“æœåŠ æƒè®¡ç®—CATEï¼Œç”¨æƒé‡æ¥å¹³è¡¡å®éªŒç»„å’Œå¯¹ç…§ç»„çš„æ ·æœ¬é‡å·®å¼‚ï¼š

<img src="./img/Basic/034.png" style="zoom:70%;" />

â€‹		g(x) ä¸ºæ ·æœ¬xè¿›å…¥å®éªŒç»„çš„å…ˆéªŒæ¦‚ç‡ï¼Œå¯ä»¥ç”¨åå˜é‡ä¼°è®¡ï¼Œå¯ä»¥ç®€åŒ–ä¸ºå®éªŒç»„å æ¯”ã€‚

**é—®é¢˜ï¼š**

- å¤šæ¨¡å‹é€ æˆè¯¯å·®ç´¯åŠ 
- **multi-treatmentå¸¦æ¥æ¨¡å‹çš„æ•°é‡å¢åŠ **

**è¯¦è§£ï¼š**

â€Xâ€œè¡¨ç¤ºäº¤å‰çš„æ„æ€ï¼Œè¯¥æ–¹æ³•ä¸»è¦è§£å†³T-Learnerå¯¹ä¸åŒTreatmentç»„ä¸Controlç»„é—´æ•°æ®é‡å·®å¼‚è¿‡å¤§æƒ…å†µè¡¨ç°ä¸ä½³çš„é—®é¢˜ã€‚å…·ä½“æ­¥éª¤ï¼š

- Step1ï¼šå¯¹Treatmentç»„æ•°æ®å’ŒControlç»„æ•°æ®åˆ†åˆ«è®­ç»ƒé¢„æµ‹æ¨¡å‹
- Step2ï¼šè®¡ç®—ä¸€ç»„upliftçš„è¿‘ä¼¼è¡¨ç¤ºçš„æ•°æ®é›†ï¼Œç”¨treatmentç»„æ¨¡å‹é¢„æµ‹controlç»„æ•°æ®ï¼Œcontrolç»„æ¨¡å‹é¢„æµ‹treatmentç»„æ•°æ®ï¼Œåˆ†åˆ«åšä¸Yçš„å·®å€¼å¾—åˆ°å¢é‡çš„è¿‘ä¼¼
- Step3:ä»¥æ­¤ä¸ºç›®æ ‡å†è®­ç»ƒé¢„æµ‹æ¨¡å‹ï¼Œæ‹Ÿåˆuplift

X-Learneråœ¨T-LearneråŸºç¡€ä¸Šï¼Œåˆ©ç”¨äº†å…¨é‡çš„æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œä¸»è¦è§£å†³**Treatmentç»„é—´æ•°æ®é‡å·®å¼‚è¾ƒå¤§çš„æƒ…å†µ**ã€‚ä½†æµç¨‹ç›¸å¯¹å¤æ‚ã€è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œæœ‰æ—¶è¿˜ä¼šç”±äºå¤šæ¨¡å‹è¯¯å·®ç´¯ç§¯ç­‰é—®é¢˜æ•ˆæœä¸ä½³ã€‚

<img src="./img/Basic/035.png" style="zoom:70%;" />

### **R-learner**

å®šä¹‰äº†ä¸€ä¸ª**æŸå¤±å‡½æ•°**ï¼Œä»¥æœ€å°åŒ–è¿™æ ·çš„ä¸€ä¸ªæŸå¤±å‡½æ•°ä¸ºç›®æ ‡æ‹ŸåˆCATEï¼š

<img src="./img/Basic/036.png" style="zoom:50%;" />

1. çº¢æ¡†(1) 
   - Yä¸ºè§‚æµ‹åˆ°çš„ç»“æœ(æ¯”å¦‚ctr labelï¼‰ 
   - m(x)ç”¨æ—¥å¸¸çš„æœºå™¨å­¦ä¹ æ¨¡å‹æ‹Ÿåˆlabelï¼Œæ•°æ®ç”¨å¯¹ç…§ç»„+å®éªŒç»„è®­ç»ƒï¼Œæè¿°æ•´ä½“æ•°æ®çš„é¢„ä¼°å‡å€¼ï¼Œçº¢æ¡†1å°±æ˜¯è¦**æ‹Ÿåˆçš„label**

2. çº¢æ¡†(2) 

   - $$W_i =1|0$$ï¼Œè¡¨ç¤ºç”Ÿæ•ˆtreatmentæˆ–controlç»„ 
   - e(x)è¡¨ç¤ºå€¾å‘æ€§è¯„åˆ†ï¼Œå¸¸ç”¨äºééšæœºå®éªŒçš„æ•°æ®ï¼›åœ¨æµé‡ç›¸åŒçš„éšæœºå®éªŒä¸­ï¼Œe(x) = 0.5å³å¯ 

   - $$\tau(x)$$åˆ™æ˜¯è¡¨ç¤ºæ¨¡å‹é¢„ä¼°çš„upliftï¼Œçº¢æ¡†2**è¡¨ç¤ºä¸ºæ¨¡å‹çš„è¾“å‡º**

3. çº¢æ¡†(3)ï¼Œæ­£åˆ™é¡¹ 

**é—®é¢˜ï¼š**

- **æ¨¡å‹ç²¾åº¦ä¾èµ–äºm(x), e(x)çš„ç²¾åº¦**ï¼›
- **multi-treatmentå¸¦æ¥æ¨¡å‹çš„æ•°é‡å¢åŠ **ã€‚

**è¯¦è§£ï¼š**

R-Learnerçš„æ€è·¯æ˜¯é€šè¿‡å°†é—®é¢˜è½¬åŒ–ä¸ºå®šä¹‰æŸå¤±å‡½æ•°(R-loss)çš„å½¢å¼è¿›è¡Œå­¦ä¹ è®­ç»ƒï¼Œæ›´å…³æ³¨â€**æ®‹å·®**â€œï¼š

Step1ï¼šé€šè¿‡äº¤å‰éªŒè¯çš„æ–¹å¼ï¼Œæ¯æ¬¡é¢„æµ‹ä¸€ç»„ï¼Œå¾—åˆ°æ•´ä¸ªæ•°æ®é›†çš„**é¢„æµ‹ç»“æœ$$m(x)$$å’Œå€¾å‘å¾—åˆ† e(x)**

$$ m(X_i)=E(Y|X_i) $$

$$ e(X_i)=E(W=1|X_i) $$

Step 2: åœ¨cvçš„å…¶ä»–ç»„æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä¼°è®¡å¢é‡ã€‚-q(i)è¡¨ç¤ºä¸åœ¨ç¬¬iç»„çš„æ ·æœ¬



## Evaluation

åœ¨upliftçš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æ— æ³•åŒæ—¶è§‚å¯Ÿåˆ°ä¸€ä¸ªä¸ªä½“çš„æœ‰treatmentå’Œæ— treatmentçš„æƒ…å†µï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦é€šè¿‡ç»Ÿè®¡ç¾¤ä½“çš„è¡¨ç°æ¥å¯¹æ¯”æ¨¡å‹çš„ä¼˜åŠ£ã€‚

### Cumulative Uplift Curve

<img src="./img/Basic/037.png" style="zoom:70%;" />

æ¨ªè½´ï¼šå°†ç”¨æˆ·ç¾¤ä½“æŒ‰ç…§æ¨¡å‹çš„é¢„ä¼°uplifté™åºæ’åºï¼ŒæŒ‰ç”¨æˆ·ä¸ªæ•°çš„åˆ†ä½æ•°åˆ†æ¡¶ã€‚å¦‚ä¸Šå›¾ä¸­ï¼Œæ¨ªè½´20ä»£è¡¨é¢„ä¼°upliftæ’åå‰20%çš„ç”¨æˆ·ã€‚

çºµè½´ï¼šx%ç”¨æˆ·treamentä¹‹åï¼Œèƒ½å¤Ÿæ‹¿åˆ°çš„revenueæ”¶ç›Šã€‚

åœ¨åæœŸï¼Œupliftä¼šä¸‹é™ï¼Œè¿™æ˜¯å› ä¸ºï¼š

- treamentæœ‰ä»£ä»·

- Sleeping dog is treated

### AUUC( Area Under Uplift Curve )

å¯¹äºYå–å€¼0-1çš„é—®é¢˜ï¼ˆæ¯”å¦‚ç‚¹å‡»æˆ–ä¸ç‚¹å‡»ï¼‰ï¼Œå¯ä»¥é€šè¿‡åˆ’åˆ†åˆ†ä½ç‚¹çš„æ–¹å¼ï¼Œå¯¹é½å®éªŒç»„å’Œå¯¹ç…§ç»„æ•°æ®è¿›è¡Œé—´æ¥è¯„ä¼°ã€‚

- ç”¨ä¼°è®¡çš„uplift score å¯¹æµ‹è¯•é›†æ ·æœ¬ç”±é«˜åˆ°ä½æ’åº, 10%, 20%
- è®¡ç®—G(top Ï†)ï¼š

<img src="./img/Basic/038.png" style="zoom:50%;" />

æ¨ªè½´ï¼šæ ·æœ¬æ’åºï¼Œçºµè½´ï¼šG(top Ï†)ï¼Œå¾—åˆ°uplift curveã€‚ç”¨æ›²çº¿ä¸random lineä¹‹é—´çš„é¢ç§¯ä½œä¸ºè¯„ä»·æ¨¡å‹è¡¨ç°çš„æŒ‡æ ‡AUUCã€‚

### Qini curve

ç±»ä¼¼uplift-curveï¼Œå¯¹Tå’ŒCæ ·æœ¬ä¸å‡åšäº†å¤„ç†ï¼Œä»¥Treatmentç»„çš„æ ·æœ¬é‡ä¸ºå‡†ï¼Œå¯¹Controlç»„åšä¸€ä¸ªç¼©æ”¾ï¼Œç´¯ç§¯ç»˜åˆ¶çš„æ›²çº¿ç§°ä¸ºQini æ›²çº¿

<img src="./img/Basic/039.png" style="zoom:50%;" />

å’ŒCumulative Uplift Curveæ€è·¯ä¸€è‡´ï¼Œåªä¸è¿‡çºµè½´å¯ä»¥æ˜¯ï¼š

- å®é™…çš„è½¬åŒ–é‡ï¼Œä¸Šå›¾å°±æ˜¯ã€‚ 

- å®é™…è½¬åŒ–ç”¨æˆ·å å…¨éƒ¨ç”¨æˆ·çš„æ¯”ä¾‹ï¼Œç›¸å½“äºå½’ä¸€åŒ–ã€‚

æ›´å¤šå‚è€ƒï¼š[Causal Inference and Uplift Modeling A review of the literature](http://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf)



## Tools

### scikit-uplift

- Docï¼šhttps://www.uplift-modeling.com/en/latest/index.html
- Codeï¼šhttps://github.com/maks-sh/scikit-uplift
- Exampleï¼š[Example](./Tools/scikit-uplift/)

### pylift

- Docï¼šhttps://pylift.readthedocs.io/en/latest/
- Codeï¼šhttps://github.com/wayfair/pylift
- Exampleï¼š[Example](./Tools/pylift/)

<img src="./img/Basic/040.png" style="zoom:50%;" />

### UpliftML

- Docï¼šhttps://upliftml.readthedocs.io/en/latest/
- Codeï¼šhttps://github.com/bookingcom/upliftml


### Causal ML Packet

#### ç®€ä»‹

**[Causal ML](https://github.com/uber/causalml)**æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œå®ƒæä¾›äº†ä¸€å¥—ä½¿ç”¨åŸºäºæœ€è¿‘ç ”ç©¶çš„æœºå™¨å­¦ä¹ ç®—æ³•çš„æå‡å»ºæ¨¡å’Œå› æœæ¨ç†æ–¹æ³•ã€‚

- **å¹¿å‘Šæ´»åŠ¨å®šä½ä¼˜åŒ–**ï¼šåœ¨å¹¿å‘Šæ´»åŠ¨ä¸­æé«˜æŠ•èµ„å›æŠ¥ç‡çš„ä¸€ä¸ªé‡è¦æ‰‹æ®µæ˜¯å°†å¹¿å‘Šå®šä½åˆ°åœ¨ç»™å®š KPIï¼ˆä¾‹å¦‚å‚ä¸åº¦æˆ–é”€å”®é‡ï¼‰ä¸­ä¼šæœ‰è‰¯å¥½ååº”çš„å®¢æˆ·ç¾¤ã€‚CATE é€šè¿‡æ ¹æ® A/B å®éªŒæˆ–å†å²è§‚å¯Ÿæ•°æ®åœ¨ä¸ªäººå±‚é¢ä¼°è®¡å¹¿å‘Šæ›å…‰çš„ KPI å½±å“æ¥è¯†åˆ«è¿™äº›å®¢æˆ·ã€‚
- **ä¸ªæ€§åŒ–å‚ä¸**ï¼šå…¬å¸æœ‰å¤šç§é€‰æ‹©ä¸å®¢æˆ·äº’åŠ¨ï¼Œä¾‹å¦‚åœ¨è¿½åŠ é”€å”®æˆ–é€šä¿¡æ¶ˆæ¯æ¸ é“ä¸­çš„ä¸åŒäº§å“é€‰æ‹©ã€‚å¯ä»¥ä½¿ç”¨ CATE æ¥ä¼°è®¡æ¯ä¸ªå®¢æˆ·å’Œæ²»ç–—é€‰é¡¹ç»„åˆçš„å¼‚è´¨æ²»ç–—æ•ˆæœï¼Œä»¥è·å¾—æœ€ä½³çš„ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€‚

The package currently supports the following methods

- Tree-based algorithms
  - Uplift tree/random forests on KL divergence, Euclidean Distance, and Chi-Square
  - Uplift tree/random forests on Contextual Treatment Selection
  - Causal Tree - Work-in-progress
- Meta-learner algorithms
  - S-learner
  - T-learner
  - X-learner
  - R-learner
  - Doubly Robust (DR) learner
  - TMLE learner
- Instrumental variables algorithms
  - 2-Stage Least Squares (2SLS)
  - Doubly Robust (DR) IV
- Neural-network-based algorithms
  - CEVAE
  - DragonNet - with `causalml[tf]` installation



#### Reference

1. Radcliffe, Nicholas J., and Patrick D. Surry. "Real-world uplift modelling with significance-based uplift trees." White Paper TR-2011-1, Stochastic Solutions (2011): 1-33.
2. Zhao, Yan, Xiao Fang, and David Simchi-Levi. "Uplift modeling with multiple treatments and general response types." Proceedings of the 2017 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2017.
3. Athey, Susan, and Guido Imbens. "Recursive partitioning for heterogeneous causal effects." Proceedings of the National Academy of Sciences 113.27 (2016): 7353-7360.
4. KÃ¼nzel, SÃ¶ren R., et al. "Metalearners for estimating heterogeneous treatment effects using machine learning." Proceedings of the national academy of sciences 116.10 (2019): 4156-4165.
5. Nie, Xinkun, and Stefan Wager. "Quasi-oracle estimation of heterogeneous treatment effects." arXiv preprint arXiv:1712.04912 (2017).
6. Bang, Heejung, and James M. Robins. "Doubly robust estimation in missing data and causal inference models." Biometrics 61.4 (2005): 962-973.
7. Van Der Laan, Mark J., and Daniel Rubin. "Targeted maximum likelihood learning." The international journal of biostatistics 2.1 (2006).
8. Kennedy, Edward H. "Optimal doubly robust estimation of heterogeneous causal effects." arXiv preprint arXiv:2004.14497 (2020).
9. Louizos, Christos, et al. "Causal effect inference with deep latent-variable models." arXiv preprint arXiv:1705.08821 (2017).
10. Shi, Claudia, David M. Blei, and Victor Veitch. "Adapting neural networks for the estimation of treatment effects." 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), 2019.



## Paper Reading

**Uplift Modelling/Causal Tree**

1. Nicholas J Radcliffe and Patrick D Surry. Real-world uplift modelling with significance based uplift trees. White Paper TR-2011-1, Stochastic Solutions, 2011.[[æ–‡ç« é“¾æ¥\]](http://stochasticsolutions.com/pdf/sig-based-up-trees.pdf)
2. Rzepakowski, P. and Jaroszewicz, S., 2012. Decision trees for uplift modeling with single and multiple treatments. Knowledge and Information Systems, 32(2), pp.303-327.[[æ–‡ç« é“¾æ¥\]](https://core.ac.uk/download/pdf/81899141.pdf)
3. Yan Zhao, Xiao Fang, and David Simchi-Levi. Uplift modeling with multiple treatments and general response types. Proceedings of the 2017 SIAM International Conference on Data Mining, SIAM, 2017. [[æ–‡ç« é“¾æ¥\]](https://dspace.mit.edu/bitstream/handle/1721.1/119250/draft_May27.pdf?sequence=1&isAllowed=y) [[Githubé“¾æ¥\]](https://github.com/uber/causalml)
4. Athey, S., and Imbens, G. W. 2015. Machine learning methods for estimating heterogeneous causal effects. stat 1050(5) [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/pdf/1810.13237.pdf)
5. Athey, S., and Imbens, G. 2016. Recursive partitioning for heterogeneous causal effects. Proceedings of the National Academy of Sciences. [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/pdf/1504.01132.pdf) [[Githubé“¾æ¥\]](https://github.com/susanathey/causalTree)
6. C. Tran and E. Zheleva, â€œLearning triggers for heterogeneous treatment effects,â€ in Proceedings of the AAAI Conference on Artificial Intelligence, 2019 [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/abs/1902.00087) [[Githubé“¾æ¥\]](https://github.com/edgeslab/CTL)

**Forest Based Estimators**

1. Wager, S. & Athey, S. (2018). Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association .
2. M. Oprescu, V. Syrgkanis and Z. S. Wu. Orthogonal Random Forest for Causal Inference. Proceedings of the 36th International Conference on Machine Learning (ICML), 2019 [[æ–‡ç« é“¾æ¥\]](http://proceedings.mlr.press/v97/oprescu19a/oprescu19a.pdf) [[GitHubé“¾æ¥\]](https://github.com/Microsoft/EconML#references)

**Double Machine Learning**

1. V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, and a. W. Newey. Double Machine Learning for Treatment and Causal Parameters. ArXiv e-prints [[æ–‡ç« é“¾æ¥\]](https://core.ac.uk/download/pdf/81899141.pdf) [[Githubé“¾æ¥\]](https://econml.azurewebsites.net/)
2. V. Chernozhukov, M. Goldman, V. Semenova, and M. Taddy. Orthogonal Machine Learning for Demand Estimation: High Dimensional Causal Inference in Dynamic Panels. ArXiv e-prints, December 2017.
3. V. Chernozhukov, D. Nekipelov, V. Semenova, and V. Syrgkanis. Two-Stage Estimation with a High-Dimensional Second Stage. 2018.
4. X. Nie and S. Wager. Quasi-Oracle Estimation of Heterogeneous Treatment Effects. arXiv preprint arXiv:1712.04912, 2017.[[æ–‡ç« è¿æ¥\]](https://arxiv.org/pdf/1712.04912.pdf)
5. D. Foster and V. Syrgkanis. Orthogonal Statistical Learning. arXiv preprint arXiv:1901.09036, 2019 [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/pdf/1901.09036.pdf)

**Meta Learner**

1. C. Manahan, 2005. A proportional hazards approach to campaign list selection. In SAS User Group International (SUGI) 30 Proceedings.
2. Green DP, Kern HL (2012) Modeling heteroge-neous treatment effects in survey experiments with Bayesian additive regression trees. Public OpinionQuarterly 76(3):491â€“511.
3. SÃ¶ren R. KÃ¼nzel, Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the National Academy of Sciences, 2019. [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/pdf/1706.03461.pdf) [[GitHubé“¾æ¥\]](https://github.com/uber/causalm)

**Deep Learning**

1. Fredrik D. Johansson, U. Shalit, D. Sontag.ICML (2016). Learning Representations for Counterfactual Inference [[æ–‡ç« é“¾æ¥\]](https://www.semanticscholar.org/paper/Learning-Representations-for-Counterfactual-Johansson-Shalit/759b00cf35b397eab468935b5d90d04e9ed25549)
2. Shalit, U., Johansson, F. D., & Sontag, D. ICML (2017). Estimating individual treatment effect: generalization bounds and algorithms. Proceedings of the 34th International Conference on Machine Learning [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/abs/1606.03976)
3. Christos Louizos, U. Shalit, J. Mooij, D. Sontag, R. Zemel, M. Welling.NIPS (2017). Causal Effect Inference with Deep Latent-Variable Models [[æ–‡ç« é“¾æ¥\]](https://www.semanticscholar.org/paper/Causal-Effect-Inference-with-Deep-Latent-Variable-Louizos-Shalit/a32a61a6bf23d13a7088f1c77e694ab13bb6c58e)
4. Alaa, A. M., Weisz, M., & van der Schaar, M. (2017). Deep Counterfactual Networks with Propensity-Dropout [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/abs/1706.05966)
5. Shi, C., Blei, D. M., & Veitch, V. NeurIPS (2019). Adapting Neural Networks for the Estimation of Treatment Effects [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/abs/1906.02120) [[Githubé“¾æ¥\]](https://github.com/claudiashi57/dragonnet)

**Uberä¸“åœº**

æœ€æ—©å°±æ˜¯uberçš„åšå®¢åœ¨èŒ«èŒ«paperçš„æµ·æ´‹ä¸­å¸®æˆ‘æ‰¾åˆ°äº†æ–¹å‘ï¼Œå¦‚ä»Šå¬è¯´å®ƒä»¬AI LABè¦è§£æ•£äº†æœ‰äº›ä¼¤æ„Ÿï¼Œä½œä¸ºHTEæœ€å¤šstarçš„å¼€æºæ–¹ï¼Œå®ƒä»¬å€¼å¾—æ‹¥æœ‰ä¸€ä¸ªpart

1. Shuyang Du, James Lee, Farzin Ghaffarizadeh, 2017, Improve User Retention with Causal Learning [[æ–‡ç« è¿æ¥\]](http://proceedings.mlr.press/v104/du19a/du19a.pdf)
2. Zhenyu Zhao, Totte Harinen, 2020, Uplift Modeling for Multiple Treatments with Cost [[æ–‡ç« è¿æ¥\]](https://arxiv.org/pdf/1908.05372.pdf)
3. Will Y. Zou, Smitha Shyam, Michael Mui, Mingshi Wang, 2020, Learning Continuous Treatment Policy and Bipartite Embeddings for Matching with Heterogeneous Causal Effects Optimization [[æ–‡ç« é“¾æ¥\]](https://arxiv.org/pdf/2004.09703.pdf)
4. Will Y. Zou,Shuyang Du,James Lee,Jan Pedersen, 2020, Heterogeneous Causal Learning for Effectiveness Optimization in User Marketing [[æ–‡ç« è¿æ¥\]](https://arxiv.org/pdf/2004.09702.pdf)
